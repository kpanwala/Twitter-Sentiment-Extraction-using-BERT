{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "BERT tweet-senti-extraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLVpcoK7zIQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "826abd09-5291-4422-c246-ce31b0d41aba"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d akensert/bert-base-uncased-huggingface-transformer\n",
        "\n",
        "!kaggle competitions download -c tweet-sentiment-extraction\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('./bert-base-uncased-huggingface-transformer.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('./train_csv.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')\n",
        "    print(\"Done...!\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done...!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "NRv5E5Y6zHKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "8tz3vv4bzHKx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "73856818-10d7-43fa-dd08-a5536e6d79d9"
      },
      "source": [
        "import pandas as pd, numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "# pip install transformers\n",
        "from transformers import *\n",
        "import tokenizers\n",
        "\n",
        "print('TF version',tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version 2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "u4PXf8JxzHK3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "f9c241f6-fc47-4bc2-be26-1eade182994b"
      },
      "source": [
        "MAX_LEN = 114\n",
        "PATH = './'\n",
        "import transformers\n",
        "\n",
        "tokenizer = tokenizers.BertWordPieceTokenizer(\n",
        "    f\"bert-base-uncased-vocab.txt\",\n",
        "    lowercase=True\n",
        ")\n",
        "\n",
        "\n",
        "train = pd.read_csv('./train.csv').fillna('')\n",
        "train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID  ... sentiment\n",
              "0  cb774db0d1  ...   neutral\n",
              "1  549e992a42  ...  negative\n",
              "2  088c60f138  ...  negative\n",
              "3  9642c003ef  ...  negative\n",
              "4  358bd9e861  ...  negative\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epm8SI1XEa83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " tokenizer.encode('positive negative neutral').ids\n",
        " sentiment_id = {'positive': 3893, 'negative': 4997, 'neutral': 8699}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FhhIFAVNzHK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ct = train.shape[0]\n",
        "input_ids = np.ones((ct,MAX_LEN),dtype='int32')\n",
        "attention_mask = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "token_type_ids = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "start_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "end_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "\n",
        "for k in range(train.shape[0]):\n",
        "    \n",
        "    # FIND OVERLAP\n",
        "    text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n",
        "    text2 = \" \".join(train.loc[k,'selected_text'].split())\n",
        "    idx = text1.find(text2)\n",
        "    chars = np.zeros((len(text1)))\n",
        "    chars[idx:idx+len(text2)]=1\n",
        "    #if text1[idx-1]==' ': chars[idx-1] = 1 \n",
        "    enc = tokenizer.encode(text1) \n",
        "        \n",
        "    # ID_OFFSETS\n",
        "    offsets = []; idx=0\n",
        "    for t in enc.ids:\n",
        "        w = tokenizer.decode([t])\n",
        "        offsets.append((idx,idx+len(w)))\n",
        "        idx += len(w)\n",
        "    \n",
        "    # START END TOKENS\n",
        "    toks = []\n",
        "    for i,(a,b) in enumerate(offsets):\n",
        "        sm = np.sum(chars[a:b])\n",
        "        if sm>0: toks.append(i) \n",
        "        \n",
        "    s_tok = sentiment_id[train.loc[k,'sentiment']]\n",
        "    input_ids[k,:len(enc.ids)+4] = [101] + enc.ids + [102] + [s_tok] + [102]\n",
        "    attention_mask[k,:len(enc.ids)+4] = 1\n",
        "    if len(toks)>0:\n",
        "        start_tokens[k,toks[0]+1] = 1\n",
        "        end_tokens[k,toks[-1]+1] = 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1jqpmlCnzHLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('./test.csv').fillna('')\n",
        "\n",
        "ct = test.shape[0]\n",
        "input_ids_t = np.ones((ct,MAX_LEN),dtype='int32')\n",
        "attention_mask_t = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "token_type_ids_t = np.zeros((ct,MAX_LEN),dtype='int32')\n",
        "\n",
        "for k in range(test.shape[0]):\n",
        "        \n",
        "    # INPUT_IDS\n",
        "    text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n",
        "    enc = tokenizer.encode(text1)                \n",
        "    s_tok = sentiment_id[test.loc[k,'sentiment']]\n",
        "    input_ids_t[k,:len(enc.ids)+4] = [101] + enc.ids + [102] + [s_tok] + [102]\n",
        "    attention_mask_t[k,:len(enc.ids)+4] = 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aR7hvtk8zHLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "\n",
        "    bert_conf = BertConfig()\n",
        "    #bert_model = transformers.BertModel(PATH+'pretrained-roberta-base.h5',config=config)\n",
        "    bert_model = TFBertModel.from_pretrained('./bert-base-uncased-tf_model.h5', config=bert_conf)\n",
        "    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n",
        "    \n",
        "    x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n",
        "    x1 = tf.keras.layers.Conv1D(1,1)(x1)\n",
        "    x1 = tf.keras.layers.Flatten()(x1)\n",
        "    x1 = tf.keras.layers.Activation('softmax')(x1)\n",
        "    \n",
        "    x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n",
        "    x2 = tf.keras.layers.Conv1D(1,1)(x2)\n",
        "    x2 = tf.keras.layers.Flatten()(x2)\n",
        "    x2 = tf.keras.layers.Activation('softmax')(x2)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "A6TEA0kRzHLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def jaccard(str1, str2): \n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    if (len(a)==0) & (len(b)==0): return 0.5\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v9DR2reCzHLM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e18c3164-e76c-4a24-f8c2-9bdd51be1bbc"
      },
      "source": [
        "jac = []; VER='v0'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\n",
        "oof_start = np.zeros((input_ids.shape[0],MAX_LEN))\n",
        "oof_end = np.zeros((input_ids.shape[0],MAX_LEN))\n",
        "preds_start = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
        "preds_end = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
        "\n",
        "skf = StratifiedKFold(n_splits=2,shuffle=True,random_state=777)\n",
        "for fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n",
        "\n",
        "    print('#'*25)\n",
        "    print('### FOLD %i'%(fold+1))\n",
        "    print('#'*25)\n",
        "    \n",
        "    K.clear_session()\n",
        "    model = build_model()\n",
        "        \n",
        "    sv = tf.keras.callbacks.ModelCheckpoint(\n",
        "        '%s-bert-%i.h5'%(VER,fold), monitor='val_loss', verbose=1, save_best_only=True,\n",
        "        save_weights_only=True, mode='auto', save_freq='epoch')\n",
        "        \n",
        "    model.fit([input_ids[idxT,], attention_mask[idxT,], token_type_ids[idxT,]], [start_tokens[idxT,], end_tokens[idxT,]], \n",
        "        epochs=3, batch_size=32, verbose=DISPLAY, callbacks=[sv],\n",
        "        validation_data=([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]], \n",
        "        [start_tokens[idxV,], end_tokens[idxV,]]))\n",
        "    \n",
        "    print('Loading model...')\n",
        "    model.load_weights('%s-bert-%i.h5'%(VER,fold))\n",
        "    \n",
        "    print('Predicting OOF...')\n",
        "    oof_start[idxV,],oof_end[idxV,] = model.predict([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]],verbose=DISPLAY)\n",
        "    \n",
        "    print('Predicting Test...')\n",
        "    preds = model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n",
        "    preds_start += preds[0]/skf.n_splits\n",
        "    preds_end += preds[1]/skf.n_splits\n",
        "    \n",
        "    # DISPLAY FOLD JACCARD\n",
        "    all = []\n",
        "    for k in idxV:\n",
        "        a = np.argmax(oof_start[k,])\n",
        "        b = np.argmax(oof_end[k,])\n",
        "        if a>b: \n",
        "            st = train.loc[k,'text'] # IMPROVE CV/LB with better choice here\n",
        "        else:\n",
        "            text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n",
        "            enc = tokenizer.encode(text1)\n",
        "            st = tokenizer.decode(enc.ids[a-1:b])\n",
        "        all.append(jaccard(st,train.loc[k,'selected_text']))\n",
        "    jac.append(np.mean(all))\n",
        "    print('>>>> FOLD %i Jaccard ='%(fold+1),np.mean(all))\n",
        "    print()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#########################\n",
            "### FOLD 1\n",
            "#########################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ./bert-base-uncased-tf_model.h5 were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the model checkpoint at ./bert-base-uncased-tf_model.h5.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "430/430 [==============================] - ETA: 0s - loss: 2.7045 - activation_loss: 1.3715 - activation_1_loss: 1.3330\n",
            "Epoch 00001: val_loss improved from inf to 2.08073, saving model to v0-bert-0.h5\n",
            "430/430 [==============================] - 786s 2s/step - loss: 2.7045 - activation_loss: 1.3715 - activation_1_loss: 1.3330 - val_loss: 2.0807 - val_activation_loss: 1.0383 - val_activation_1_loss: 1.0424\n",
            "Epoch 2/3\n",
            "430/430 [==============================] - ETA: 0s - loss: 1.9996 - activation_loss: 1.0138 - activation_1_loss: 0.9859\n",
            "Epoch 00002: val_loss improved from 2.08073 to 1.97456, saving model to v0-bert-0.h5\n",
            "430/430 [==============================] - 784s 2s/step - loss: 1.9996 - activation_loss: 1.0138 - activation_1_loss: 0.9859 - val_loss: 1.9746 - val_activation_loss: 0.9914 - val_activation_1_loss: 0.9832\n",
            "Epoch 3/3\n",
            "430/430 [==============================] - ETA: 0s - loss: 1.6344 - activation_loss: 0.8280 - activation_1_loss: 0.8064\n",
            "Epoch 00003: val_loss did not improve from 1.97456\n",
            "430/430 [==============================] - 783s 2s/step - loss: 1.6344 - activation_loss: 0.8280 - activation_1_loss: 0.8064 - val_loss: 2.1235 - val_activation_loss: 1.0432 - val_activation_1_loss: 1.0803\n",
            "Loading model...\n",
            "Predicting OOF...\n",
            "430/430 [==============================] - 198s 461ms/step\n",
            "Predicting Test...\n",
            "111/111 [==============================] - 51s 457ms/step\n",
            ">>>> FOLD 1 Jaccard = 0.5122473649230872\n",
            "\n",
            "#########################\n",
            "### FOLD 2\n",
            "#########################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ./bert-base-uncased-tf_model.h5 were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the model checkpoint at ./bert-base-uncased-tf_model.h5.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "430/430 [==============================] - ETA: 0s - loss: 2.7819 - activation_loss: 1.3920 - activation_1_loss: 1.3899\n",
            "Epoch 00001: val_loss improved from inf to 2.11740, saving model to v0-bert-1.h5\n",
            "430/430 [==============================] - 788s 2s/step - loss: 2.7819 - activation_loss: 1.3920 - activation_1_loss: 1.3899 - val_loss: 2.1174 - val_activation_loss: 1.0611 - val_activation_1_loss: 1.0563\n",
            "Epoch 2/3\n",
            "430/430 [==============================] - ETA: 0s - loss: 2.0474 - activation_loss: 1.0204 - activation_1_loss: 1.0270\n",
            "Epoch 00002: val_loss improved from 2.11740 to 2.01223, saving model to v0-bert-1.h5\n",
            "430/430 [==============================] - 785s 2s/step - loss: 2.0474 - activation_loss: 1.0204 - activation_1_loss: 1.0270 - val_loss: 2.0122 - val_activation_loss: 1.0298 - val_activation_1_loss: 0.9824\n",
            "Epoch 3/3\n",
            "430/430 [==============================] - ETA: 0s - loss: 1.6710 - activation_loss: 0.8359 - activation_1_loss: 0.8351\n",
            "Epoch 00003: val_loss did not improve from 2.01223\n",
            "430/430 [==============================] - 783s 2s/step - loss: 1.6710 - activation_loss: 0.8359 - activation_1_loss: 0.8351 - val_loss: 2.0726 - val_activation_loss: 1.0590 - val_activation_1_loss: 1.0136\n",
            "Loading model...\n",
            "Predicting OOF...\n",
            "430/430 [==============================] - 198s 461ms/step\n",
            "Predicting Test...\n",
            "111/111 [==============================] - 51s 456ms/step\n",
            ">>>> FOLD 2 Jaccard = 0.5071351954938963\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "w5zsoUPbzHLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4c746cfd-a8b4-4b0b-ef6e-cd9327e0422f"
      },
      "source": [
        "print('>>>> OVERALL 3Fold CV Jaccard =',np.mean(jac))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>>> OVERALL 3Fold CV Jaccard = 0.5096912802084917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PLt7Yon-zHLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all = []\n",
        "for k in range(input_ids_t.shape[0]):\n",
        "    a = np.argmax(preds_start[k,])\n",
        "    b = np.argmax(preds_end[k,])\n",
        "    if a>b: \n",
        "        st = test.loc[k,'text']\n",
        "    else:\n",
        "        text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n",
        "        enc = tokenizer.encode(text1)\n",
        "        st = tokenizer.decode(enc.ids[a-1:b])\n",
        "    st.replace(\"##\",\"\")\n",
        "    all.append(st)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-W7uBkPczHLW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "outputId": "0554d36a-98e3-4f59-909d-97816b3d0b0d"
      },
      "source": [
        "test['selected_text'] = all\n",
        "test[['textID','selected_text']].to_csv('submission.csv',index=False)\n",
        "pd.set_option('max_colwidth', 60)\n",
        "test.sample(25)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>selected_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3290</th>\n",
              "      <td>edef02e047</td>\n",
              "      <td>_7 Wow that`s a big list...lol. I would be happy if I go...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>7 wow that ` s a big list... lol. i would be happy if i ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584</th>\n",
              "      <td>4f7cba2eff</td>\n",
              "      <td>ach, probably not... they are labeled as MI-5, which I ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>ach, probably not... they are labeled as mi - 5, which i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1476</th>\n",
              "      <td>d72748e39c</td>\n",
              "      <td>u never sent me carrie. ur an ****. but an **** that i ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>miss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661</th>\n",
              "      <td>bcf13877f7</td>\n",
              "      <td>Good morning everyone</td>\n",
              "      <td>positive</td>\n",
              "      <td>good morning everyone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2027</th>\n",
              "      <td>7907132523</td>\n",
              "      <td>In bed with 2 girls</td>\n",
              "      <td>neutral</td>\n",
              "      <td>in bed with 2 girls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004</th>\n",
              "      <td>bfb0644d9e</td>\n",
              "      <td>I love Dawn Chorus noisier the better miss Church Bells...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>love dawn chorus noisier the better miss church bells to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1259</th>\n",
              "      <td>1900a6978a</td>\n",
              "      <td>Idk i cant do ****</td>\n",
              "      <td>negative</td>\n",
              "      <td>idk i cant do * * * *</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1725</th>\n",
              "      <td>07c4438a0a</td>\n",
              "      <td>plus I just deposited tax return cheque but for first t...</td>\n",
              "      <td>negative</td>\n",
              "      <td>clear immediately</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1143</th>\n",
              "      <td>4d7def819d</td>\n",
              "      <td>Aw, sorry E. :/ I hope it looks up for you (lame ear) A...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>aw, sorry e. : / i hope it looks up for you ( lame ear )...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2390</th>\n",
              "      <td>f765bed159</td>\n",
              "      <td>oh mann... Me likey that!! But sadly I`m not bein aucti...</td>\n",
              "      <td>negative</td>\n",
              "      <td>sadly i ` m not bei</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3510</th>\n",
              "      <td>bbfe533366</td>\n",
              "      <td>In my moms hair salon, dying my hair</td>\n",
              "      <td>neutral</td>\n",
              "      <td>in my moms hair salon, dying my hair</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3404</th>\n",
              "      <td>b5eb308679</td>\n",
              "      <td>browsin thru the videos in my multiply and i saw the vid...</td>\n",
              "      <td>negative</td>\n",
              "      <td>you, n. we all miss you. pls come back wherever u r.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2252</th>\n",
              "      <td>1f45286504</td>\n",
              "      <td>Alix`s graduation party!</td>\n",
              "      <td>neutral</td>\n",
              "      <td>alix ` s graduation party!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2385</th>\n",
              "      <td>3c4cd5a819</td>\n",
              "      <td>my house is so sad looking without all of the furniture,...</td>\n",
              "      <td>negative</td>\n",
              "      <td>looking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2267</th>\n",
              "      <td>59d4b58ebd</td>\n",
              "      <td>thanks man!  I appreciate it!  You rock sir.</td>\n",
              "      <td>positive</td>\n",
              "      <td>thanks man! i appreciate it! you rock sir.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1369</th>\n",
              "      <td>2b8b0a7d10</td>\n",
              "      <td>Is twubbing again</td>\n",
              "      <td>neutral</td>\n",
              "      <td>is twubbing again</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2302</th>\n",
              "      <td>2ea6cb3bd3</td>\n",
              "      <td>Has got to go to work with a slight hangover gd nite thou</td>\n",
              "      <td>neutral</td>\n",
              "      <td>has got to go to work with a slight hangover gd nite thou</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2937</th>\n",
              "      <td>3f8fc09752</td>\n",
              "      <td>Anyone have a Super Nintendo Controller they want to sel...</td>\n",
              "      <td>negative</td>\n",
              "      <td>broke.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>00d5195223</td>\n",
              "      <td>Cramps . . .</td>\n",
              "      <td>negative</td>\n",
              "      <td>cramps...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1328</th>\n",
              "      <td>07ae045cbe</td>\n",
              "      <td>that was delicious! lets have a walk sometimes with you...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>that was delicious! lets have a walk sometimes with you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>5ffb19ae8f</td>\n",
              "      <td>Gnight shar   &lt;(` `&lt;)Vega(&gt;` `)&gt;</td>\n",
              "      <td>neutral</td>\n",
              "      <td>##night shar &lt; ( ` ` &lt; ) vega ( &gt; ` ` ) &gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>8a821c6d63</td>\n",
              "      <td>LOL, very true. Maybe next year. I loooved that siggy, ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>LOL, very true. Maybe next year. I loooved that siggy, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1221</th>\n",
              "      <td>ffcd5cb36e</td>\n",
              "      <td>11:11 pm Perrrfect universal alignment.    &lt;33</td>\n",
              "      <td>neutral</td>\n",
              "      <td>11 : 11 pm perrrfect universal alignment. &lt; 33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1057</th>\n",
              "      <td>6aa5004916</td>\n",
              "      <td>11 Days left until freedom. I really just want to get th...</td>\n",
              "      <td>negative</td>\n",
              "      <td>essays.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2251</th>\n",
              "      <td>081a4e8b31</td>\n",
              "      <td>i cant believe that its already friday! omg, what had i ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>cant believe that its already friday! omg, what had i do...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          textID  ...                                                selected_text\n",
              "3290  edef02e047  ...  7 wow that ` s a big list... lol. i would be happy if i ...\n",
              "584   4f7cba2eff  ...  ach, probably not... they are labeled as mi - 5, which i...\n",
              "1476  d72748e39c  ...                                                         miss\n",
              "661   bcf13877f7  ...                                        good morning everyone\n",
              "2027  7907132523  ...                                          in bed with 2 girls\n",
              "2004  bfb0644d9e  ...  love dawn chorus noisier the better miss church bells to...\n",
              "1259  1900a6978a  ...                                        idk i cant do * * * *\n",
              "1725  07c4438a0a  ...                                            clear immediately\n",
              "1143  4d7def819d  ...  aw, sorry e. : / i hope it looks up for you ( lame ear )...\n",
              "2390  f765bed159  ...                                          sadly i ` m not bei\n",
              "3510  bbfe533366  ...                         in my moms hair salon, dying my hair\n",
              "3404  b5eb308679  ...         you, n. we all miss you. pls come back wherever u r.\n",
              "2252  1f45286504  ...                                   alix ` s graduation party!\n",
              "2385  3c4cd5a819  ...                                                      looking\n",
              "2267  59d4b58ebd  ...                   thanks man! i appreciate it! you rock sir.\n",
              "1369  2b8b0a7d10  ...                                            is twubbing again\n",
              "2302  2ea6cb3bd3  ...    has got to go to work with a slight hangover gd nite thou\n",
              "2937  3f8fc09752  ...                                                       broke.\n",
              "17    00d5195223  ...                                                    cramps...\n",
              "1328  07ae045cbe  ...  that was delicious! lets have a walk sometimes with you ...\n",
              "89    5ffb19ae8f  ...                    ##night shar < ( ` ` < ) vega ( > ` ` ) >\n",
              "279   8a821c6d63  ...   LOL, very true. Maybe next year. I loooved that siggy, ...\n",
              "1221  ffcd5cb36e  ...               11 : 11 pm perrrfect universal alignment. < 33\n",
              "1057  6aa5004916  ...                                                      essays.\n",
              "2251  081a4e8b31  ...  cant believe that its already friday! omg, what had i do...\n",
              "\n",
              "[25 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6VPzjfJlvc0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "8ca83e4f-71a7-4856-8b2f-a32baa5d5e79"
      },
      "source": [
        "pd.read_csv('submission.csv')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>selected_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f87dea47db</td>\n",
              "      <td>last session of the day http : / / twitpic. com / 67ez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>96d74cb729</td>\n",
              "      <td>##weeps in china</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eee518ae67</td>\n",
              "      <td>shame!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01082688c6</td>\n",
              "      <td>happy bday!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33987a8ee5</td>\n",
              "      <td>##w75p - i like</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3529</th>\n",
              "      <td>e5f0e6ef4b</td>\n",
              "      <td>tired but i can</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3530</th>\n",
              "      <td>416863ce47</td>\n",
              "      <td>for the net</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3531</th>\n",
              "      <td>6332da480c</td>\n",
              "      <td>depression... he wants to move someplace tropical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3532</th>\n",
              "      <td>df1baec676</td>\n",
              "      <td>videos!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3533</th>\n",
              "      <td>469e15c5a8</td>\n",
              "      <td>##woj2 - omgssh ang cute</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3534 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          textID                                           selected_text\n",
              "0     f87dea47db  last session of the day http : / / twitpic. com / 67ez\n",
              "1     96d74cb729                                        ##weeps in china\n",
              "2     eee518ae67                                                  shame!\n",
              "3     01082688c6                                             happy bday!\n",
              "4     33987a8ee5                                         ##w75p - i like\n",
              "...          ...                                                     ...\n",
              "3529  e5f0e6ef4b                                         tired but i can\n",
              "3530  416863ce47                                             for the net\n",
              "3531  6332da480c       depression... he wants to move someplace tropical\n",
              "3532  df1baec676                                                 videos!\n",
              "3533  469e15c5a8                                ##woj2 - omgssh ang cute\n",
              "\n",
              "[3534 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}